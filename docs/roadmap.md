## Overview

- Links

DLSlime is dedicated to supporting efficient transmission over a variety of different links, including but not limited to IBVerbs, CUDA IPC, TCP Socket, PCIE, NVShmem, Ascend (Direct) ...

- Transfer Engine

DLSlime provides a flexible and efficient P2P Transfer Engine, enabling AI-workload-aware customized functions such as Prefill-Decode separation and checkpoint transmission.

- Collective Ops

Referring to [DeepEP](https://github.com/deeplink-org/DeepEP.git), DLSlime provides a buffer-based collective communication library that achieves ultra-low latency collective communications.

- Torch Wrapper

To meet the heterogeneous requirements of SPMD programs such as heterogeneous pipeline parallel training, a Torch communication backend is provided.

## Transfer Engine Roadmap

- IBVerbs Transfer Engine
  - ‚úÖ SendRecv Endpoint
  - ‚úÖ RDMA Read/Write Endpoint
- NVShmem
  - ‚úÖ NVShmem Context and Send/Recv Kernel
  - ‚ö° support NVShmem put and get wrapper
- TCP Socket
  - ‚úÖ zmq bootstrap
  - ‚è≥ TCP Socket transfer engine
- CUDA IPC
  - ‚úÖ support CUDAIPC Read/Write Endpoint
- PCIE
  - ‚è≥ High performance Shared Memory transfer engine
  - ‚è≥ High performance data offloading
- Ascend
  - ‚úÖ Ascned direct transfer engine
- UB Mesh
  - üí≠ Planning

## Collective Ops

- IBVerbs
  - ‚úÖ Send/Recv
  - ‚ö° M2N for attention-FFN disaggregation
  - ‚è≥ AllGather
  - ‚è≥ AllReduce
  - ‚è≥ All2All
- NVShmem
  - ‚è≥ Send/Recv
  - üöß AllGather
- CUDA IPC
  - ‚úÖ AllGather
  - ‚úÖ High performance AllGather using CUDA Multi-Mem

## Torch Wrapper

- IBVerbs
  - ‚úÖ Send/Recv
  - ‚è≥ AllGather
  - ‚è≥ AllReduce
  - ‚è≥ All2All
